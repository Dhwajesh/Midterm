---
title: "Midterm"
author: "Dhwajesh Bhandari"
output: html_document
date: "2024-11-04"
---

```{r}
#load library
library(readr)
library(fpp2)
library(ggplot2)



##Load data and assign column names
data_sales <- read.csv("sales.csv", header=FALSE)
colnames(data_sales) <- c("date", "sales")



##Convert sales column to time series & plot the time series
sales_ts <- ts(data_sales$sales, start = c(2020, 1), frequency = 12)
plot(sales_ts)



##Central Tendencies
summary(sales_ts)



## Seasonal and Trend decomposition
stl_decom<-stl(sales_ts,s.window = "periodic")
plot(stl_decom)

# Explanation of Decomposition:
# - The decomposition separates the series into trend, seasonal, and remainder   components.
# - Trend: this component shows the underlying direction of the data. It is upwards and slightly dips after reaching its peak in 2023.
# - Seasonal: through this, it uncovers the repeating patterns within a period.
# - Remainder : remainder or residual component show random fluctuations that aren't explained by trend nor by seasonality.
#STL Decomposition Type:
# The decomposition  suggests that the seasonal component does not change over the series.
#The seasonal effect does not vary with the trend, so an additive model should work.
#For an additive model, the seasonal fluctuations must be constant in magnitude, which fits well with the described behavior of a stable seasonal pattern here.
#Hence, additive decomposition is used here, since this type of decomposition correctly models the seasonal pattern in this data

##Seasonal indices
seasonal_indices <- stl_decom$time.series[, "seasonal"]
print(seasonal_indices)
#The seasonal component has monthly indices that describe normal deviations from the trend each month.
#High/Low Seasonal Values: The month containing the highest seasonal value identifies the peak in sales, while the low identifies a drop in sales.

## High and low seasonal months
high_value <- max(seasonal_indices)
low_value <- min(seasonal_indices)
high_month <- which(seasonal_indices == high_value)[1]
low_month <- which(seasonal_indices == low_value)[1]

##High and Low Seasonal Months Explanation
#- High months usually fall on peak demand periods: holiday seasons and end-of-year sales are two obvious examples.
#Low months would then reflect the months of low demand, probably due to low seasonal activities or market factors.
cat("High sales month:", high_month, "with value:", high_value, "\n")
cat("Low sales month:", low_month, "with value:", low_value, "\n")
# Adjusting for seasonality
seasonally_adj_sales <- sales_ts - seasonal_indices
plot(sales_ts, col = "yellow", main = "Actual vs. Seasonally Adjusted Sales")
lines(seasonally_adj_sales, col = "red", lty = 2)
legend("topright", legend = c("Actual Sales", "Seasonally Adjusted Sales"), col = c("yellow", "red"), lty = c(1, 2))
#Seasonally adjusted plot explanation:
#Overlay: Actual Sales vs. Seasonally Adjusted Sales. The differences between the two series show the impact of seasonality.
#The influence will then be strongly seasonal if large fluctuations between the actual and seasonally adjusted series take place.
#It eliminates seasonality and can, potentially, highlight more about the trend and irregular variation that may be useful for prediction.



#load forecast library
library(forecast)

#naive forecast
sales_naive<-naive(sales_ts,h=12)
plot(sales_naive, main= "Forecast by naive method", ylab ="Sales")
#The Naive method assumes that future values will be identical to the most recent observed value. It serves as a simple benchmark, providing a straightforward approach to forecasting with minimal calculations. It is particularly useful for data exhibiting random walks or non-trending time series.

# Residual Analysis:
residual_naive<-residuals(sales_naive)
hist(sales_naive$residuals, main = "Residuals", xlab = "Residuals")
# Plot of Residuals:Visual inspection of residuals aids in identifying any unexplained systematic patterns in the data. A random scatter around zero without discernible patterns suggests that the Naive model has successfully captured the underlying structure in the data.

# ACF plot of residuals
Acf(sales_naive$residuals, main = "ACF of Residuals")
#The ACF plot visually examines the correlations among residuals at various lags. A lack of significant autocorrelations suggests that the residuals are uncorrelated, implying a good fit for the model.

# accuracy metrics for the Naive forecast
accuracy_value <- accuracy(sales_naive)
print(accuracy_value)

sales_naive_nextyear <- forecast(sales_naive)
plot(sales_naive_nextyear)
#Using the naive method, we project future values by keeping the most recent observed value as the prediction for each subsequent time point.

# Summary of the Naive Forecasting Technique
#The Naive method is a straightforward forecasting technique that assigns each future value the same as the most recent observed value. It serves as a fundamental benchmark, especially useful for time series data lacking significant trends or seasonal patterns.

# How good is the accuracy?
#Based on the accuracy metrics, the Naive method offers a straightforward forecast, but its accuracy may not be the best for data with patterns.
#RMSE (Root Mean Squared Error) indicates moderate error levels, reflecting the average size of the forecast error.
#MAE (Mean Absolute Error) shows deviations from actual values and provides a more straightforward measure of absolute forecast error.
#MAPE (Mean Absolute Percentage Error) expresses the error as a percentage, making it easier to understand relative forecast accuracy.
#ACF1 suggests low to moderate autocorrelation, indicating that the model does not systematically under- or over-forecast.
#Overall, while the Naive method may be suitable for simple data sets, it might not be the most accurate choice for data with patterns or complex relationships.

# What does it predict the time series value will be in one year?
#The naive forecast assumes that the value will remain constant at the last observed sales figure for the next 12 months. Consequently, it projects a stable, flat forecast line for the upcoming year, assuming no changes or trends in the data.

# Other Observations:
#The Naive forecast serves as a benchmark model, offering a straightforward prediction that can be used to compare against more sophisticated models. Although it provides a reliable prediction, the Naive approach may not adequately capture underlying trends or seasonal patterns, resulting in higher forecast errors if these patterns exist in the data.


# Simple Moving Average of order 3
ma3 <- ma(sales_ts, order = 3)
lines(ma3, col = "red", lty = 1)  # Adding MA(3) in red

# Simple Moving Average of order 6
ma6 <- ma(sales_ts, order = 6)
lines(ma6, col = "yellow", lty = 2)  # Adding MA(6) in blue

# Simple Moving Average of order 9
ma9 <- ma(sales_ts, order = 9)
lines(ma9, col = "green", lty = 3)  # Adding MA(9) in green

# Adding a legend to distinguish between different moving averages
legend("topright", legend = c("Original Series", "MA(3)", "MA(6)", "MA(9)"),
       col = c("black", "red", "yellow", "green"), lty = c(1, 1, 2, 3))

#Moving average forecast
maf_sales<-ma(sales_ts,order=12)
plot(maf_sales, main="Forecast by moving average", ylab="Sales")
residual_maf<-sales_ts-maf_sales
plot(residual_maf, main="Forecast by moving average residual", ylab="Sales")
# Observations on Moving Averages
#As the moving average order increases from 3 to 6 to 9, the plot becomes progressively smoother. Lower-order moving averages (e.g., MA(3)) are more sensitive to short-term fluctuations, while higher orders (e.g., MA(9)) focus on the overall trend. However, higher-order moving averages reduce noise but introduce a lag effect, making the trend more prominent but slower to respond to recent changes. This progression demonstrates how moving averages effectively visualize both short-term variations and long-term trends, depending on the chosen order.


#Exponential smoothing forecast
sales_ses<-ses(sales_ts,h=12)
summary(sales_ses)
plot(sales_ses, main="Forecast by simple smoothing method", ylab="sales")
# Explanation of summary
#Alpha: The smoothing parameter, derived from the data, determines the weight given to recent values in the forecast. In this case, alpha is set to 0.4319, indicating a moderate level of responsiveness to recent data points.
#Initial State: The initial level of the series, which can be found in the summary output, serves as the starting point for the forecast. It provides a base level from which the forecast will be generated.
#Sigma: Sigma represents the residual standard deviation, which quantifies the forecast uncertainty. A lower sigma indicates a higher level of reliability in the forecast.

#Residuals
residual_ses<-residuals(sales_ses)
hist(sales_ses$residuals, main = "Histogram of Residuals", xlab = "Residuals")
#This plot aids in visualizing any discernible patterns in the residuals. A random scatter around zero suggests that the model has effectively captured most of the patterns in the data, while systematic patterns indicate that the model might be missing some underlying trends.

# ACF of Residuals
Acf(sales_ses$residuals, main = "ACF of Residuals for Simple Smoothing Forecast")
#Examines the residual correlations at various lags. 

# Display accuracy measures for the Simple Smoothing forecast
accuracy(sales_ses)
#The accuracy metrics, including RMSE, MAE, and MAPE, offer valuable insights into the model’s precision. Moderate values for RMSE and MAE indicate a reasonable fit, although further improvement may be achievable by incorporating trend-accounting models. Additionally, a low ACF1 value suggests minimal autocorrelation in the residuals, which further supports the model’s adequacy.

# Forecast for the Next 12 Months and Explanation
sales_sesforecast <- forecast(sales_ses, h = 12)
print(sales_sesforecast)
plot(sales_sesforecast, main = "Simple Smoothing Forecast for Next Year")
#The forecast plot for the next 12 months includes shaded areas that represent 80% and 95% confidence intervals. These intervals indicate the range within which future values are expected, reflecting the forecast uncertainty.

#Here’s a summary of the Simple Smoothing Technique:
#Interpretation of Forecast: The forecast suggests that sales will stabilize around the last observed level, with only minor fluctuations.
#Predicted Values: The predicted values imply that sales will remain stable in the coming year, assuming that there are no new trends or seasonal changes.
#Suitability: Simple Exponential Smoothing is suitable for relatively stable data without strong trends or seasonality.
#Limitations: It is effective for short-term forecasting but may not fully capture complex patterns such as seasonality or trends.



#HoltsWinter forecast
sales_hw<-hw(sales_ts)
sales_hw_forecast <- forecast(sales_hw, h = 12)
plot(sales_hw,main="Forecast by Holtswinter",ylab="Sales")
summary(sales_hw)
# Holt-Winters Model Parameters and Output:
#Alpha: This parameter controls the smoothness of the forecasted level. A higher alpha value makes the forecast more responsive to recent changes.
#Beta:Beta adjusts the smoothness of the trend. Higher beta values make the trend more sensitive to recent data.
#Gamma:Gamma determines the weight of seasonal patterns. A higher gamma value allows the model to adapt more quickly to seasonal changes.
#Initial States:These are the starting points for the level, trend, and seasonal components of the forecast. They are derived from the data and serve as the foundation for the forecast.
#Sigma:Sigma represents the standard deviation of the residuals, which indicates the uncertainty in the forecast. Lower sigma values suggest a more stable model

residuals_hw<-residuals(sales_hw)
plot(residuals_hw,main="Forecast by HoltsWinter residual",ylab="Sales")
# Explanation: Random scatter around zero with no obvious patterns indicates a well-fitting model.


# ACF of Residuals
Acf(sales_hw_forecast$residuals, main = "ACF of Residuals for Holt-Winters Forecast")
accuracy(sales_hw_forecast)
print(sales_hw_forecast)
plot(sales_hw_forecast, main = "Holt-Winters Forecast", ylab = "Sales", xlab = "Time")
#The absence of autocorrelations in the residuals indicates that the model effectively captures the underlying structure of the data.

# Forecast Interpretation
#This plot presents the Holt-Winters forecast for the next 12 months, encompassing both trend and seasonality. The shaded areas indicate the forecast intervals (80% and 95%), encompassing the anticipated range of future values. Additionally, the forecast accuracy measures (RMSE, MAE, MAPE) offer valuable insights into the model’s predictive performance. Furthermore, the lower residual autocorrelation (ACF1) and low sigma values further validate the model’s effectiveness in accurately capturing seasonal patterns and trends.



#MAPE 
mape_naive <- accuracy(sales_naive)[, "MAPE"]
mape_ses <- accuracy(sales_ses)[, "MAPE"]
mape_hw <- accuracy(sales_hw_forecast)[, "MAPE"]

# Moving Average does not produce a forecast object directly, so we use an alternate approach for MAPE
maf_sales <- ts(ma(sales_ts, order = 12), start = c(2020, 1), frequency = 12)
mape_ma <- mean(abs((sales_ts - maf_sales) / sales_ts), na.rm = TRUE) * 100

# Combine MAPE values
mape_table <- data.frame(
  Model = c("Naive", "Moving Average", "SES", "Holt-Winters"),
  MAPE = c(mape_naive, mape_ma, mape_ses, mape_hw)
)
mape_table <- mape_table[order(mape_table$MAPE), ]  
print(mape_table)



#Forecasting Methods: Definitions and Applications
#1. Naive Forecasting: This approach assumes that future values will be identical to the most recent observed value. It’s useful for datasets with high randomness or when recent data points are the best indicators of future values. It serves as a simple benchmark to assess the performance of more complex models.
#2. Simple Moving Average (SMA): The SMA method calculates the average of a specified, fixed number of previous observations. It’s useful for smoothing out short-term fluctuations and revealing longer-term trends. It’s particularly useful for stable datasets with minimal trend or seasonal patterns.
#3. Simple Exponential Smoothing (SES): SES assigns exponentially decreasing weights to past observations, emphasizing recent data points more heavily. It’s suitable for short-term forecasting in data that lacks trend or seasonality, as it adjusts to changes in the data level without considering trends.
#4. Holt-Winters Method: The Holt-Winters method is an extension of exponential smoothing that includes adjustments for both trend and seasonality. It’s ideal for time series data with both trend and seasonal variations, capturing these changes through its trend (beta) and seasonal (gamma) components.
#5. STL Decomposition: STL decomposition is a technique used to decompose a time series into three components: seasonal, trend, and remainder. It’s useful for identifying seasonal patterns and trends in time series data.

##Best and Worst Forecast Models for Each Accuracy Measure:
#Best Forecast Model: Simple Exponential Smoothing (SES) achieves the lowest Mean Absolute Percentage Error (MAPE) at 15.49. This makes it the most accurate model in minimizing relative error in this dataset.
#Worst Forecast Model: The Mean model has the highest MAPE at 140, indicating its least effectiveness as a forecasting approach, especially for data with trends or seasonality.

#Interpretation:
#SES Model: The low MAPE for SES reflects its ability to handle moderate variability in data. It is effective for datasets without strong seasonal or trend components.
#Mean Model: The high MAPE for the Mean model suggests it is unsuitable for data with trends or seasonality. It fails to account for recent changes in the data pattern.


##This analysis highlights the strengths and limitations of each forecasting method. The SES model demonstrates precision for short-term projections, while the Mean model’s limitations are evident in more dynamic datasets.





```

